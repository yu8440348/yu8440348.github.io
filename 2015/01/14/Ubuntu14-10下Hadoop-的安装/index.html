
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>Ubuntu14.10下Hadoop 单机的安装 | 一个程序员</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="YuHaiTao">
    

    
    <meta name="description" content="环境 系统： Ubuntu 14.04 64bit Hadoop版本： Hadoop 2.6.0 (stable) JDK版本： sun jdk7  安装SSH server、配置SSH无密码登陆安装 ssh 和 rsync ssh 是一个很著名的安全外壳协议 Secure Shell Protocol。 rsync 是文件同步命令行工具">
<meta name="keywords" content="Hadoop,Ubuntu">
<meta property="og:type" content="article">
<meta property="og:title" content="Ubuntu14.10下Hadoop 单机的安装">
<meta property="og:url" content="http://kuailelai.com/2015/01/14/Ubuntu14-10下Hadoop-的安装/index.html">
<meta property="og:site_name" content="一个程序员">
<meta property="og:description" content="环境 系统： Ubuntu 14.04 64bit Hadoop版本： Hadoop 2.6.0 (stable) JDK版本： sun jdk7  安装SSH server、配置SSH无密码登陆安装 ssh 和 rsync ssh 是一个很著名的安全外壳协议 Secure Shell Protocol。 rsync 是文件同步命令行工具">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2015-12-02T15:58:44.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ubuntu14.10下Hadoop 单机的安装">
<meta name="twitter:description" content="环境 系统： Ubuntu 14.04 64bit Hadoop版本： Hadoop 2.6.0 (stable) JDK版本： sun jdk7  安装SSH server、配置SSH无密码登陆安装 ssh 和 rsync ssh 是一个很著名的安全外壳协议 Secure Shell Protocol。 rsync 是文件同步命令行工具">

    
    <link rel="alternative" href="/atom.xml" title="一个程序员" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="一个程序员" title="一个程序员"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="一个程序员">一个程序员</a></h1>
				<h2 class="blog-motto">程序员是值得尊敬的，程序员的双手是魔术师的双手。他们把枯燥无味的代码变成了丰富多彩的软件</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">主页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/categories">分类</a></li>
					
						<li><a href="/about">关于</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:kuailelai.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/01/14/Ubuntu14-10下Hadoop-的安装/" title="Ubuntu14.10下Hadoop 单机的安装" itemprop="url">Ubuntu14.10下Hadoop 单机的安装</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="YuHaiTao" target="_blank" itemprop="author">YuHaiTao</a>
		
  <p class="article-time">
    <time datetime="2015-01-14T08:45:00.000Z" itemprop="datePublished"> 发表于 2015-01-14</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#环境"><span class="toc-number">1.</span> <span class="toc-text">环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装SSH-server、配置SSH无密码登陆"><span class="toc-number">2.</span> <span class="toc-text">安装SSH server、配置SSH无密码登陆</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装-ssh-和-rsync"><span class="toc-number">2.1.</span> <span class="toc-text">安装 ssh 和 rsync</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-java-implementation-to-use"><span class="toc-number"></span> <span class="toc-text">The java implementation to use.</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-集群配置"><span class="toc-number">1.</span> <span class="toc-text">hadoop 集群配置</span></a></li></ol>
		
		</div>
		
		<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>系统： Ubuntu 14.04 64bit</li>
<li>Hadoop版本： Hadoop 2.6.0 (stable)</li>
<li>JDK版本： sun jdk7</li>
</ul>
<h2 id="安装SSH-server、配置SSH无密码登陆"><a href="#安装SSH-server、配置SSH无密码登陆" class="headerlink" title="安装SSH server、配置SSH无密码登陆"></a>安装SSH server、配置SSH无密码登陆</h2><h3 id="安装-ssh-和-rsync"><a href="#安装-ssh-和-rsync" class="headerlink" title="安装 ssh 和 rsync"></a>安装 ssh 和 rsync</h3><blockquote>
<p>ssh 是一个很著名的安全外壳协议 Secure Shell Protocol。 rsync 是文件同步命令行工具<br><a id="more"></a><br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ssh rsync</span><br><span class="line">```  </span><br><span class="line">### 配置 ssh 免登录</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>ssh-keygen -t dsa -f ~/.ssh/id_dsa<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> 执行这条命令生成 ssh 的公钥/私钥,执行过程中,会一些提示让输入字符,直接一路回车就可以</span></span><br></pre></td></tr></table></figure></p>
<p>cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> ssh 进行远程登录的时候需要输入密码,如果用公钥/私钥方式,就不需要输入密码了。上述方式就是设置公钥/私钥登录。</span></span><br></pre></td></tr></table></figure></p>
<p>ssh localhost<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> 第一次执行本命令,会出现一个提示,输入 ” yes”然后回车即可</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 安装Hadoop 2.6.0</span></span></span><br><span class="line">下载Hadoop 2.6.0后,解压到/usr/local/中。</span><br></pre></td></tr></table></figure></p>
<p>sudo tar -zxvf ~/下载/hadoop-2.6.0.tar.gz -C /usr/local   # 解压到/usr/local中<br>sudo mv /usr/local/hadoop-2.6.0/ /usr/local/hadoop      # 将文件名改为hadoop<br>sudo chown -R yuhaitao:yuhaitao /usr/local/hadoop       # 修改文件权限<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> yuhaitao 为当前登录用户</span></span><br><span class="line"></span><br><span class="line">Hadoop解压后即可使用。输入如下命令Hadoop检查是否可用，成功则会显示命令行的用法：</span><br></pre></td></tr></table></figure></p>
<p>/usr/local/hadoop/bin/hadoop<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">### Hadoop单机配置</span><br></pre></td></tr></table></figure></p>
<p>cd /usr/local/hadoop<br>mkdir input<br>cp etc/hadoop/<em>.xml input<br>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output ‘dfs[a-z.]+’<br>cat ./output/</em><br><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">执行成功后输出的结果是符合正则的单词dfsadmin出现了<span class="number">1</span>次  </span><br><span class="line">再次运行会提示出错，需要将./<span class="keyword">output</span>删除。</span><br></pre></td></tr></table></figure></p>
<p>rm -R ./output<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 配置java路径</span><br><span class="line">编辑 hadoop/etc/hadoop/hadoop-env.sh, 修改java路径</span><br></pre></td></tr></table></figure></p>
<h1 id="The-java-implementation-to-use"><a href="#The-java-implementation-to-use" class="headerlink" title="The java implementation to use."></a>The java implementation to use.</h1><p>export JAVA_HOME=/usr/app/java<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 配置环境变量</span></span><br><span class="line">&gt; 为什么是profile文件，而不是~/.bashrc文件</span><br><span class="line">/etc/profile:此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行.并从/etc/profile.d目录的配置文件中搜集shell的设置.</span><br><span class="line">~/.bashrc:该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取.（每个用户都有一个.bashrc文件，在用户目录下）</span><br><span class="line">另外,/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承/etc/profile中的变量,他们是”父子”关系.</span><br><span class="line">Hadoop可以在单节点上以伪分布式的方式运行，Hadoop进程以分离的Java进程来运行，节点即是NameNode也是DataNode。需要修改2个配置文件etc/hadoop/core-site.xml和etc/hadoop/hdfs-site.xml。Hadoop的配置文件是xml格式，声明property的name和value。</span><br><span class="line"></span><br><span class="line">vim <span class="built_in">/profile </span>设置环境变量</span><br></pre></td></tr></table></figure></p>
<p>export HADOOP_HOME=/usr/local/hadoop<br>export PATH=$PATH:$HADOOP_HOME/bin<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">3</span>:让文件生效</span><br></pre></td></tr></table></figure></p>
<p>source /etc/profile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">输入 hadoop，显示如下，表示配置成功</span><br></pre></td></tr></table></figure></p>
<p>Usage: hadoop [–config confdir] COMMAND<br>       where COMMAND is one of:<br>  fs                   run a generic filesystem user client<br>  version              print the version<br>  jar <jar>            run a jar file<br>  checknative [-a|-h]  check native hadoop and compression libraries availability<br>  distcp <srcurl> <desturl> copy file or directories recursively<br>  archive -archiveName NAME -p <parent path=""> <src>* <dest> create a hadoop archive<br>  classpath            prints the class path needed to get the<br>  credential           interact with credential providers<br>                       Hadoop jar and the required libraries<br>  daemonlog            get/set the log level for each daemon<br>  trace                view and modify Hadoop tracing settings<br> or<br>  CLASSNAME            run the class named CLASSNAME</dest></src></parent></desturl></srcurl></jar></p>
<p>Most commands print help when invoked w/o parameters.</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">修改配置文件etc<span class="regexp">/hadoop/</span>core-site.xml，将</span><br></pre></td></tr></table></figure>
<p><configuration><br></configuration><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修改为下面配置：</span><br></pre></td></tr></table></figure></p>
<p><configuration><br>    <property><br>        <name>hadoop.tmp.dir</name><br>        <value>file:/usr/local/hadoop/tmp</value><br>        <description>Abase for other temporary directories.</description><br>    </property><br>    <property><br>        <name>fs.default.name</name><br>        <value>hdfs://localhost:9000</value><br>    </property><br></configuration><br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修改配置文件etc<span class="regexp">/hadoop/</span>hdfs-site.xml为</span><br></pre></td></tr></table></figure></p>
<p><configuration><br>    <property><br>        <name>dfs.replication</name><br>        <value>1</value><br>    </property><br>    <property><br>        <name>dfs.namenode.name.dir</name><br>        <value>file:/usr/local/hadoop/tmp/dfs/name</value><br>    </property><br>    <property><br>        <name>dfs.datanode.data.dir</name><br>        <value>file:/usr/local/hadoop/tmp/dfs/data</value><br>    </property></configuration></p>
<pre><code>#启用webhdfs，可用web接口管理hdfs文件系统
&lt;property&gt;
       &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
       &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
</code></pre><p><br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">关于配置的一点说明：上面只要配置 fs<span class="selector-class">.defaultFS</span> 和 dfs<span class="selector-class">.replication</span> 就可以运行，不过有个说法是如没有配置 hadoop<span class="selector-class">.tmp</span><span class="selector-class">.dir</span> 参数，此时 Hadoop 默认的使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在每次重启后都会被干掉，必须重新执行 format 才行（未验证），所以伪分布式配置中最好还是设置一下。此外也需要显式指定 dfs<span class="selector-class">.namenode</span><span class="selector-class">.name</span><span class="selector-class">.dir</span> 和 dfs<span class="selector-class">.datanode</span><span class="selector-class">.data</span><span class="selector-class">.dir</span>，否则下一步可能会出错。</span><br><span class="line"></span><br><span class="line">配置完成后，首先初始化文件系统 HDFS:</span><br></pre></td></tr></table></figure></p>
<p>bin/hdfs namenode -format<br><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; 成功的话，最后的提示如下，Exitting with <span class="keyword">status</span> <span class="number">0</span> 表示成功，Exitting with <span class="keyword">status</span> <span class="number">1</span>: 则是出错。若出错，可试着加上 sudo, 既 sudo bin/hdfs namenode -<span class="keyword">format</span> 试试看。</span><br><span class="line"></span><br><span class="line">接着开启NaneNode和DataNode守护进程。</span><br></pre></td></tr></table></figure></p>
<p>sbin/start-dfs.sh<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">若出现下面SSH的提示，输入yes即可。</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> 成功启动后，可以通过命令jps看到启动了如下进程NameNode、DataNode和SecondaryNameNode。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> 此时可以访问Web界面http://localhost:50070来查看Hadoop的信息。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Hadoop伪分布式实例-WordCount</span></span></span><br><span class="line">首先创建所需的几个目录</span><br></pre></td></tr></table></figure></p>
<p>bin/hdfs dfs -mkdir /user<br>bin/hdfs dfs -mkdir /user/hadoop<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">接着将etc<span class="regexp">/hadoop中的文件作为输入文件复制到分布式文件系统中，即将/</span>usr<span class="regexp">/local/</span>hadoop<span class="regexp">/etc/</span>hadoop复制到分布式文件系统中的<span class="regexp">/user/</span>hadoop<span class="regexp">/input中。上一步创建的 /</span>user<span class="regexp">/hadoop 相当于 HDFS 中的用户当前目录，可以看到复制文件时无需指定绝对目录，下面的命令的目标路径就是 /</span>user<span class="regexp">/hadoop/</span><span class="string">input:</span></span><br></pre></td></tr></table></figure></p>
<p>bin/hdfs dfs -put etc/hadoop input<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">运行MapReduce作业，执行成功的话跟单机模式相同，输出作业信息。</span><br></pre></td></tr></table></figure></p>
<p>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output ‘dfs[a-z.]+’<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看运行结果</span><br></pre></td></tr></table></figure></p>
<p>bin/hdfs dfs -cat output/*<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">也可以将运行结果取回到本地。</span><br></pre></td></tr></table></figure></p>
<p>rm -R ./output<br>bin/hdfs dfs -get output output<br>cat ./output/*<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">结束Hadoop进程，则运行</span><br></pre></td></tr></table></figure></p>
<p>sbin/stop-dfs.sh<br><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt; 注意  </span><br><span class="line">下次再启动hadoop，无需进行HDFS的初始化，只需要运行 sbin/<span class="built_in">stop</span>-dfs.sh 就可以！</span><br><span class="line"></span><br><span class="line"><span class="comment">## 附加教程</span></span><br><span class="line">解决 sbin/<span class="built_in">start</span>-dfs.sh中的warn提示</span><br><span class="line"></span><br><span class="line">提示ssh: Could <span class="keyword">not</span> <span class="built_in">resolve</span> hostname *: Name <span class="keyword">or</span> service <span class="keyword">not</span> known</span><br><span class="line"></span><br><span class="line">首先输入命令hostname看下自己的机器名，如我这边是powerxing-M1。修改/etc/hosts，将<span class="number">127.0</span><span class="number">.1</span><span class="number">.1</span> powerxing-M1改成<span class="number">192.168</span><span class="number">.1</span><span class="number">.121</span> powerxing-M1，即本机地址。</span><br><span class="line"></span><br><span class="line">提示WARN util.NativeCodeLoader: Unable <span class="built_in">to</span> <span class="built_in">load</span> native-hadoop library <span class="keyword">for</span> your <span class="built_in">platform</span>… <span class="keyword">using</span> builtin-java classes where applicable</span><br><span class="line"></span><br><span class="line">这是因为hadoop native library是<span class="number">32</span>位系统编译的，在<span class="number">64</span>位系统上会有这个提示，需要下载hadoop的源码重新编译，可参考  <span class="keyword">http</span>://stackoverflow.com/questions/<span class="number">19943766</span>/hadoop-unable-<span class="built_in">to</span>-<span class="built_in">load</span>-native-hadoop-library-<span class="keyword">for</span>-your-<span class="built_in">platform</span>-error-<span class="keyword">on</span>-centos</span><br><span class="line"></span><br><span class="line">我已经在Ubuntu <span class="number">14.04</span> <span class="number">64</span>bit上编译过了，可下载我编译的进行覆盖。</span><br><span class="line"></span><br><span class="line">下载地址: <span class="keyword">http</span>://pan.baidu.com/s/<span class="number">1</span>c0AJ3Gk</span><br><span class="line"></span><br><span class="line">下载后执行如下命令，替换掉原来的navtive library。</span><br></pre></td></tr></table></figure></p>
<p>rm -R /usr/local/hadoop/lib<br>tar -zxvf ~/下载/lib.tar.gz -C /usr/local/hadoop<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 编译 Hadoop 源码</span></span><br><span class="line">若想自己编译源码，需安装 g++ 和 Protocol Buffers（若访问不了可点此下载http:<span class="regexp">//</span>pan.baidu.com<span class="regexp">/s/</span><span class="number">1</span>ntIAoVR）：</span><br></pre></td></tr></table></figure></p>
<p>sudo tar -zxvf ~/下载/protobuf-2.5.0.tar.gz -C /usr/local<br>sudo apt-get install g++<br>cd /usr/local/protobuf-2.5.0<br>sudo ./configure<br>sudo make<br>sudo make check<br>sudo make install<br>protoc –-version<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最后一行代码应输出 protoc 的版本信息，若不能运行，则执行：</span><br></pre></td></tr></table></figure></p>
<p>sudo ldconfig<br>protoc –-version<br><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">若提示出错错误 “protoc: <span class="literal">error</span> <span class="keyword">while</span> loading <span class="keyword">shared</span> libraries: libprotoc.so.<span class="number">8</span>: cannot <span class="keyword">open</span> <span class="keyword">shared</span> object <span class="keyword">file</span>: No such <span class="keyword">file</span> <span class="keyword">or</span> directory”。则执行：</span><br></pre></td></tr></table></figure></p>
<p>export LD_LIBRARY_PATH=/usr/local/lib/<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">安装后切换到 Hadoop 源码目录下，执行：</span><br></pre></td></tr></table></figure></p>
<p>cd ~/hadoop-2.4.1-src<br>mvn package -Pdist,native -DskipTests -Dtar<br><code>`</code><br>编译完成后，在 hadoop-2.4.1-src/hadoop-dist/target 可看到。</p>
<h2 id="hadoop-集群配置"><a href="#hadoop-集群配置" class="headerlink" title="hadoop 集群配置"></a>hadoop 集群配置</h2><p><a href="http://www.powerxing.com/install-hadoop-cluster-2-4-1/" target="_blank" rel="noopener">http://www.powerxing.com/install-hadoop-cluster-2-4-1/</a></p>
<blockquote>
<p>本文转载自 <a href="http://www.powerxing.com/install-hadoop-2-4-1-single-node/" target="_blank" rel="noopener">http://www.powerxing.com/install-hadoop-2-4-1-single-node/</a></p>
</blockquote>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Hadoop/">Hadoop</a><a href="/tags/Ubuntu/">Ubuntu</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://kuailelai.com/2015/01/14/Ubuntu14-10下Hadoop-的安装/" data-title="Ubuntu14.10下Hadoop 单机的安装 | 一个程序员" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/01/16/HDFS-java-API增删改查操作/" title="HDFS java API增删改查操作">
  <strong>上一篇：</strong><br/>
  <span>
  HDFS java API增删改查操作</span>
</a>
</div>


<div class="next">
<a href="/2015/01/13/ubuntu配置vsftp/"  title="ubuntu配置vsftp">
 <strong>下一篇：</strong><br/> 
 <span>ubuntu配置vsftp
</span>
</a>
</div>

</nav>

	

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#环境"><span class="toc-number">1.</span> <span class="toc-text">环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装SSH-server、配置SSH无密码登陆"><span class="toc-number">2.</span> <span class="toc-text">安装SSH server、配置SSH无密码登陆</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装-ssh-和-rsync"><span class="toc-number">2.1.</span> <span class="toc-text">安装 ssh 和 rsync</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-java-implementation-to-use"><span class="toc-number"></span> <span class="toc-text">The java implementation to use.</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop-集群配置"><span class="toc-number">1.</span> <span class="toc-text">hadoop 集群配置</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/编程相关/" title="编程相关">编程相关<sup>5</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Ubuntu/" title="Ubuntu">Ubuntu<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/Java开发/" title="Java开发">Java开发<sup>11</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/fedora/" title="fedora">fedora<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/hexo/" title="hexo">hexo<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Hadoop/" title="Hadoop">Hadoop<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/日志/" title="日志">日志<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/git/" title="git">git<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hbase/" title="hbase">hbase<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/hive/" title="hive">hive<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/markdown/" title="markdown">markdown<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> 生当作人杰 <br/>
			死亦为鬼雄</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/1179900904" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2018 
		
		<a href="/about" target="_blank" title="YuHaiTao">YuHaiTao</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>









<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
